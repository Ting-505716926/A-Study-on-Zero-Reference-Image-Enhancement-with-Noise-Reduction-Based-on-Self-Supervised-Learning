{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from model2 import enhance_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizeData(data):\n",
    "    return (data - tf.math.reduce_min(data)) / (tf.math.reduce_max(data) - tf.math.reduce_min(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_selection(enhancement_images):\n",
    "    images = []\n",
    "    for index, i in enumerate(enhancement_images):\n",
    "        r,g,b = tf.split(i, 3, axis=2)\n",
    "        r_g = int(np.abs(np.mean(r*0.299-g*0.587)))\n",
    "        r_b = int(np.abs(np.mean(r*0.299-b*0.114)))\n",
    "        g_b = int(np.abs(np.mean(g*0.587-b*0.114)))\n",
    "        \n",
    "        img = tf.image.rgb_to_hsv(i)\n",
    "        h,s,v = tf.split(img, 3, axis=2)\n",
    "        mean_hue = tf.math.reduce_mean(h*255)\n",
    "        mean_v = tf.math.reduce_mean(v)\n",
    "        \n",
    "        if 22 < mean_hue and mean_hue <= 100:\n",
    "            if 30 <= mean_v and mean_v <= 145:\n",
    "                if  5<=r_g and  r_g <= 36: \n",
    "                    if 5 <= r_b and r_b<=48:\n",
    "                        if 5 <= g_b and  g_b <= 75:\n",
    "                            images.append(i)\n",
    "                            print(index)\n",
    "    if np.shape(images)[0] == 0:\n",
    "        return enhancement_images[0:5]\n",
    "    return images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ['DCE_Denoised_noactivate']\n",
    "model_name = model_name[0]\n",
    "add_noise = True\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 'finish'\n",
    "enhancement_path = './model/{0}/enhancment/weights/{1}/'.format(model_name, i)\n",
    "# denoising_path = './model/{0}/denoising/weights/epoch{1}/'.format(model_name, i)\n",
    "model = enhance_net(input_shape=(None,None,3), model_name=model_name, train=False, add_noise=add_noise)\n",
    "model.enhancement_net.load_weights(enhancement_path)\n",
    "# model.denoising_net.load_weights(denoising_path)\n",
    "\n",
    "img_dir = './Dataset/test2/'\n",
    "output_dir = './result/{0}/{1}/'.format(model_name, i)\n",
    "\n",
    "folder = os.path.exists(output_dir)\n",
    "if not folder:\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for file in os.listdir(img_dir):\n",
    "    img_path = img_dir + file\n",
    "    img = cv2.imread(img_path)\n",
    "    cv2.imwrite(output_dir+file, img)\n",
    "    \n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)/255\n",
    "    h,w,c = np.shape(img)\n",
    "    img = tf.reshape(img, (1,h,w,c))\n",
    "    pred_img = tf.cast(img, dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "\n",
    "    parameter_map, noise, denoise = model.predict(pred_img)\n",
    "    \n",
    "    pred_img = denoise\n",
    "    \n",
    "    # pred_img = tf.cast((denoise) * 255, dtype=tf.int8)\n",
    "    # print(tf.reduce_min(pred_img))\n",
    "    # pred_img = tf.cast(pred_img/255, dtype=tf.float32)\n",
    "    \n",
    "        \n",
    "    denoise = np.reshape(denoise, (h,w,c))\n",
    "    denoise = cv2.cvtColor(denoise, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(output_dir + file[:-4] + 'denoise.jpg', denoise*255)\n",
    "    \n",
    "    noise = np.reshape(noise, (h,w,c))\n",
    "    noise = cv2.cvtColor(noise, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(output_dir + file[:-4] + 'noise.jpg', noise*255)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ----------------對low-light Image增強----------------\n",
    "    enhancement_images = []\n",
    "    for i in range(8):\n",
    "        pred_img = pred_img + parameter_map * (pred_img - tf.math.pow(pred_img, 2))\n",
    "        pred_img = NormalizeData(pred_img)\n",
    "        enhancement_image = np.reshape(pred_img, (h,w,c))*255\n",
    "        # cv2.imwrite(\"./image/test/{0}.jpg\".format(i+1), cv2.cvtColor(np.asarray(enhancement_image), cv2.COLOR_RGB2BGR))\n",
    "        enhancement_images.append(enhancement_image)\n",
    "    # -----------------------end--------------------------\n",
    "    \n",
    "    parameter_map = np.reshape(parameter_map, (h,w,c))\n",
    "    parameter_map = cv2.cvtColor(parameter_map, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(output_dir + file[:-4] + 'parameter_map.jpg', parameter_map*255)\n",
    "    \n",
    "    # ------------------------圖像挑選--------------------\n",
    "    # enhancement_images = image_selection(enhancement_images)\n",
    "    # print(file)\n",
    "    # print(np.shape(enhancement_images))\n",
    "    # ----------------------------------------------------\n",
    "    \n",
    "    \n",
    "    # ------------Merge using Exposure Fusion-------------\n",
    "    # print(\"Merging using Exposure Fusion ... \")\n",
    "    mergeMertens = cv2.createMergeMertens()\n",
    "    exposureFusion = mergeMertens.process(enhancement_images[:5])\n",
    "    # plt.imshow(exposureFusion)\n",
    "    # plt.show()\n",
    "\n",
    "    # Save output image\n",
    "    # print(\"Saving output ... exposure-fusion.jpg\")\n",
    "    exposureFusion = cv2.cvtColor(exposureFusion,cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(output_dir + file[:-4]+'exposure-fusion.png', exposureFusion*255)\n",
    "    # -----------------------end--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a480b68b8c343a8999e692c3d6d2f5bf9e4da97c94672fb67f8d413f9dcb69e4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('tf26')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
