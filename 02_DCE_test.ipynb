{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import PIL.Image as Image\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from enhanced_model import enhance_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizeData(data):\n",
    "    return (data - tf.math.reduce_min(data)) / (tf.math.reduce_max(data) - tf.math.reduce_min(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_selection(enhancement_images):\n",
    "    images = []\n",
    "    select_img = []\n",
    "    select_img_safe = [[],[],[],[],[],[],[],[]]\n",
    "    for index, i in enumerate(enhancement_images):\n",
    "        r,g,b = tf.split(i, 3, axis=2)\n",
    "        r_g = int(np.abs(np.mean(r*0.299-g*0.587)))\n",
    "        r_b = int(np.abs(np.mean(r*0.299-b*0.114)))\n",
    "        g_b = int(np.abs(np.mean(g*0.587-b*0.114)))\n",
    "        \n",
    "        img = tf.image.rgb_to_hsv(i)\n",
    "        h,s,v = tf.split(img, 3, axis=2)\n",
    "        mean_hue = tf.math.reduce_mean(h*255)\n",
    "        mean_v = tf.math.reduce_mean(v)\n",
    "        \n",
    "\n",
    "        if 22 < mean_hue and mean_hue <= 100:\n",
    "            select_img_safe[index].append('hue')\n",
    "            if 30 <= mean_v and mean_v <= 145:\n",
    "                select_img_safe[index].append('lightness')\n",
    "                if  5<=r_g and  r_g <= 36: \n",
    "                    select_img_safe[index].append('r-g')\n",
    "                    if 5 <= r_b and r_b<=48:\n",
    "                        select_img_safe[index].append('r-b')\n",
    "                        if 5 <= g_b and  g_b <= 75:\n",
    "                            select_img_safe[index].append('g-b')\n",
    "                            images.append(i)\n",
    "                            select_img.append(index)\n",
    "    if np.shape(images)[0] == 0:\n",
    "        print(select_img_safe)\n",
    "        return enhancement_images[0:5]\n",
    "    print(select_img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ['DCE', 'CSP_DCE', 'MSP_DCE','DCE++']\n",
    "model_name = model_name[1]\n",
    "\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10\n",
    "path = './model/{0}/weights/epoch{1}/'.format(model_name, i)\n",
    "# path = './model/DCE_1_10_5_1600/weights/epoch{0}/'.format(i)\n",
    "model = enhance_net(input_shape=(None,None,3), model_name=model_name)\n",
    "model.enhancement_net.load_weights(path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = './Dataset/denoise/LOL/train/low/'\n",
    "# img_dir = './result/paper_use/Visual Comparisons/low/output/'\n",
    "# img_dir = 'C://Users/user/Downloads/mh/'\n",
    "output_dir = './result/{0}/epoch{1}/'.format(model_name, i)\n",
    "\n",
    "folder = os.path.exists(output_dir)\n",
    "if not folder:\n",
    "    os.makedirs(output_dir)\n",
    "for i in range(5):\n",
    "    strat = time.time()\n",
    "    for file in os.listdir(img_dir):\n",
    "        img_path = img_dir + file\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)/255\n",
    "        \n",
    "        h,w,c = np.shape(img)\n",
    "        img = tf.reshape(img, (1,h,w,c))\n",
    "        img = tf.cast(img, dtype=tf.float32)\n",
    "        \n",
    "        enhancemnet_image, parameter_map = model.predict(img)\n",
    "        \n",
    "        enhancemnet_image = NormalizeData(enhancemnet_image)\n",
    "        enhancemnet_image = np.reshape(enhancemnet_image, (h,w,c))\n",
    "        enhancemnet_image = cv2.cvtColor(enhancemnet_image, cv2.COLOR_RGB2BGR)\n",
    "        # cv2.imwrite(output_dir +file, enhancemnet_image*255)\n",
    "\n",
    "    end = time.time()\n",
    "    per_image_time = (end - strat)/len(os.listdir(img_dir))\n",
    "    print(per_image_time)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 2\n",
    "for i in range(10,101,10):\n",
    "    path = './model/{0}/weights/epoch{1}/'.format(model_name, i)\n",
    "    # path = './model/DCE_1_10_5_1600/weights/epoch{0}/'.format(i)\n",
    "    model = enhance_net(input_shape=(None,None,3), model_name=model_name)\n",
    "    model.enhancement_net.load_weights(path)    \n",
    "    \n",
    "    # img_dir = './Dataset/denoise/LOL/train/low/'\n",
    "    img_dir = './Dataset/denoise/test/low/'\n",
    "    # img_dir = 'C://Users/user/Downloads/mh/'\n",
    "    output_dir = './result/{0}/epoch{1}/'.format(model_name, i)\n",
    "\n",
    "    folder = os.path.exists(output_dir)\n",
    "    if not folder:\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    strat = time.time()\n",
    "    for file in os.listdir(img_dir):\n",
    "        img_path = img_dir + file\n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)/255\n",
    "        h,w,c = np.shape(img)\n",
    "        img = tf.reshape(img, (1,h,w,c))\n",
    "        pred_img = tf.cast(img, dtype=tf.float32)\n",
    "        \n",
    "        \n",
    "        enhancemnet_image, parameter_map = model.predict(pred_img)\n",
    "    \n",
    "        enhancemnet_image = NormalizeData(enhancemnet_image)\n",
    "        enhancemnet_image = np.reshape(enhancemnet_image, (h,w,c))\n",
    "        enhancemnet_image = cv2.cvtColor(enhancemnet_image, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(output_dir +file, enhancemnet_image*255)\n",
    "    \n",
    "    \n",
    "        # ----------------對low-light Image增強----------------\n",
    "        # enhancement_images = []\n",
    "        # for i in range(8):\n",
    "        #     pred_img = pred_img + parameter_map * (pred_img - tf.math.pow(pred_img, 2))\n",
    "        #     # pred_img = NormalizeData(pred_img)\n",
    "        #     enhancement_image = np.reshape(pred_img, (h,w,c))*255\n",
    "        #     cv2.imwrite(\"./result/test/{0}_{1}\".format(i+1,file), cv2.cvtColor(np.asarray(enhancement_image), cv2.COLOR_RGB2BGR))\n",
    "        #     enhancement_images.append(enhancement_image)\n",
    "        # -----------------------end--------------------------\n",
    "    \n",
    "    \n",
    "        # # ------------------------\n",
    "        # print(file, end=' ')\n",
    "        # print(np.shape(enhancement_images), end = '')\n",
    "        # enhancement_images = image_selection(enhancement_images)\n",
    "        # # ------------------------\n",
    "        \n",
    "        \n",
    "        # # ------------Merge using Exposure Fusion-------------\n",
    "        # # print(\"Merging using Exposure Fusion ... \")\n",
    "        # mergeMertens = cv2.createMergeMertens()\n",
    "        # exposureFusion = mergeMertens.process(enhancement_images[-2:])\n",
    "        # # plt.imshow(exposureFusion)\n",
    "        # # plt.show()\n",
    "\n",
    "        # # Save output image\n",
    "        # # print(\"Saving output ... exposure-fusion.jpg\")\n",
    "        # exposureFusion = cv2.cvtColor(exposureFusion,cv2.COLOR_BGR2RGB)\n",
    "        # cv2.imwrite(output_dir + file[:-4]+'exposure-fusion.png', exposureFusion*255)\n",
    "        # # -----------------------end--------------------------\n",
    "        \n",
    "    end = time.time()\n",
    "    per_image_time = (end - strat)/len(os.listdir(img_dir))\n",
    "    print(per_image_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import PIL.Image as Image\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from model import enhance_net\n",
    "\n",
    "def NormalizeData(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "model_name = ['DCE', 'CSP_DCE','MSP_DCE', 'DCE++']\n",
    "model_name = model_name[1]\n",
    "\n",
    "print(model_name)\n",
    "\n",
    "i = 10\n",
    "path = './model/{0}/weights/epoch{1}/'.format('MSP_DCE', i)\n",
    "model = enhance_net(input_shape=(None,None,3), model_name=model_name)\n",
    "model.enhancement_net.load_weights(path) \n",
    "\n",
    "img_path = './result/paper_use/Visual Quality Evaluation/low/778.png'\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)/255\n",
    "h,w,c = np.shape(img)\n",
    "img = tf.reshape(img, (1,h,w,c))\n",
    "pred_img = tf.cast(img, dtype=tf.float32)\n",
    "\n",
    "enhancement_image, parameter_map = model.predict(pred_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhancement_image = np.reshape(enhancement_image, (h,w,c))\n",
    "enhancement_image = cv2.cvtColor(enhancement_image, cv2.COLOR_RGB2BGR)\n",
    "enhancement_image = NormalizeData(enhancement_image)\n",
    "cv2.imwrite('enhanced_img.png', enhancement_image*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_map = np.reshape(parameter_map, (h,w,c))\n",
    "parameter_map = cv2.cvtColor(parameter_map, cv2.COLOR_RGB2BGR)\n",
    "p_r, p_g, p_b = cv2.split(parameter_map)\n",
    "p_r = NormalizeData(p_r)\n",
    "p_g = NormalizeData(p_g)\n",
    "p_b = NormalizeData(p_b)\n",
    "cv2.imwrite('parameter_map_R.png', p_r*255)\n",
    "cv2.imwrite('parameter_map_G.png', p_g*255)\n",
    "cv2.imwrite('parameter_map_B.png', p_b*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(p_r, cmap='gray')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(p_g, cmap='gray')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(p_b, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A13,A24 = np.split(parameter_map,2,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1,A3 = np.split(A13,2,axis=1)\n",
    "A2,A4 = np.split(A24,2,axis=1)\n",
    "\n",
    "cv2.imwrite('parameter_map.png', parameter_map*255)\n",
    "cv2.imwrite('A1.png', A1*255)\n",
    "cv2.imwrite('A2.png', A2*255)\n",
    "cv2.imwrite('A3.png', A3*255)\n",
    "cv2.imwrite('A4.png', A4*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(A1, cmap='gray')\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(A2, cmap='gray')\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(A3, cmap='gray')\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(A4, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a480b68b8c343a8999e692c3d6d2f5bf9e4da97c94672fb67f8d413f9dcb69e4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('tf26')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
