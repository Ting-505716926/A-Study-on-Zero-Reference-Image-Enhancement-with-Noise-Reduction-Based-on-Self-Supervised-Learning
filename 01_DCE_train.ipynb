{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow_addons.optimizers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enhanced_model import enhance_net\n",
    "from utils.training_process import training_process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 8\n",
    "# 各模型極限batch size(3080Ti-12GB)\n",
    "model_name = ['DCE','CSP_DCE', \"MSP_DCE\",'DCE++']\n",
    "model_name = model_name[1]\n",
    "add_noise = True\n",
    "lr = 0.0001\n",
    "# input_shape = (512,512,3)\n",
    "model_path = './model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(image):\n",
    "    image = tf.cast(image/255. ,tf.float32)\n",
    "    return image\n",
    "\n",
    "def process2(image, image2):\n",
    "    image = tf.cast(image/255. ,tf.float32)\n",
    "    image2 = tf.cast(image2/255. ,tf.float32)\n",
    "    return image, image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_path = './Dataset/train'\n",
    "# validation_path = './Dataset/validation/'\n",
    "# validation_label_path = './Dataset/validation_label/'\n",
    "\n",
    "train_path = './Dataset/denoise/LOL/train/low/'\n",
    "validation_path = './Dataset/denoise/LOL/test/low/'\n",
    "validation_label_path = './Dataset/denoise/LOL/test/high/'\n",
    "\n",
    "size = 510\n",
    "\n",
    "trainset = image_dataset_from_directory(train_path,\n",
    "                                        labels=None,\n",
    "                                        label_mode=None,\n",
    "                                        color_mode='rgb',\n",
    "                                        class_names=None,\n",
    "                                        image_size=(size,size),\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=False)\n",
    "\n",
    "valset = image_dataset_from_directory(validation_path,\n",
    "                                      seed=1,\n",
    "                                      labels=None,\n",
    "                                      label_mode=None,\n",
    "                                      color_mode='rgb',\n",
    "                                      class_names=None,\n",
    "                                      image_size=(size,size),\n",
    "                                      batch_size=batch_size)\n",
    "\n",
    "val_label = image_dataset_from_directory(validation_label_path,\n",
    "                                         seed=1,\n",
    "                                         labels=None,\n",
    "                                         label_mode=None,\n",
    "                                         color_mode='rgb',\n",
    "                                         class_names=None,\n",
    "                                         image_size=(size,size),\n",
    "                                         batch_size=batch_size)\n",
    "\n",
    "valset = tf.data.Dataset.zip((valset, val_label))\n",
    "valset = valset.map(process2)\n",
    "trainset = trainset.map(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterators = len(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = enhance_net(input_shape=(None,None,3), model_name=model_name)\n",
    "model.enhancement_net.summary()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=AdamW(learning_rate=lr,\n",
    "                              clipvalue=0.1,\n",
    "                              weight_decay=0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i + 1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def show_predictions(dataset=None, num=1):\n",
    "    clear_output(wait=True)\n",
    "    for image in dataset.take(num):\n",
    "        enhancemnet_image, _ = model.predict(image)\n",
    "        display([image[0], enhancemnet_image[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ssim = 0\n",
    "best_psnr = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if epoch != 0:\n",
    "        print()\n",
    "    print('Epoch:{0}/{1}'.format(epoch+1,epochs))\n",
    "    \n",
    "    strat = time.time()\n",
    "    # 預設最多會有10個評估參數\n",
    "    mean_loss = np.zeros(10)\n",
    "    \n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, x_batch_train in enumerate(trainset):\n",
    "        # 呼叫訓練\n",
    "        dict = model.train_step(x_batch_train)  \n",
    "        \n",
    "        # 輸出訓練過程(Epoch、step、time、total loss等參數)\n",
    "        mean_loss = training_process(step, mean_loss, dict, len(trainset), strat, mode=1)  \n",
    "    training_process(step, mean_loss, dict, len(trainset), strat, mode=2)\n",
    "    \n",
    "    show_predictions(trainset)\n",
    "    \n",
    "    mean_ssim = 0\n",
    "    mean_psnr = 0\n",
    "    for val, label in valset:\n",
    "        ssim, psnr = model.validation_step(val, label)\n",
    "        mean_ssim += ssim\n",
    "        mean_psnr += psnr\n",
    "    mean_ssim /= len(val_label)\n",
    "    mean_psnr /= len(val_label)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    if mean_ssim > best_ssim and mean_psnr > best_psnr:\n",
    "        best_ssim = mean_ssim\n",
    "        best_psnr = mean_psnr\n",
    "        model.model_save(epoch, model_path)\n",
    "        print('save_model', end=' ')\n",
    "        print('ssim: {0:6f} - psnr: {1:6f}'.format(best_ssim, best_psnr))\n",
    "    else:\n",
    "        print('ssim: {0:6f} - psnr: {1:6f}'.format(mean_ssim, mean_psnr))\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print()\n",
    "        model.model_save(epoch, model_path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a480b68b8c343a8999e692c3d6d2f5bf9e4da97c94672fb67f8d413f9dcb69e4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('tf26')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
